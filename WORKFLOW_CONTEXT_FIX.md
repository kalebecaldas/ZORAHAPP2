# üîß Corre√ß√£o do Problema de Contexto no Workflow

## üìã **Problema Identificado**

Quando o usu√°rio fazia perguntas sequenciais sobre procedimentos, o bot perdia o contexto:

```
USER: qual valor da acupuntura?
BOT: üíâ Acupuntura - R$ 180,00/sess√£o ‚úÖ

USER: e o da fisioterapia?
BOT: üìç Localiza√ß√£o das Nossas Unidades ‚ùå (ERRADO!)
```

## üîç **Diagn√≥stico**

### O que estava acontecendo:

1. ‚úÖ Usu√°rio pergunta sobre **acupuntura** ‚Üí Bot responde corretamente com **pre√ßos**
2. ‚úÖ Workflow salva o pr√≥ximo n√≥ (`gpt_classifier`) no banco de dados
3. ‚úÖ Usu√°rio pergunta "e o da fisioterapia?"
4. ‚úÖ Workflow carrega e volta para `gpt_classifier`
5. ‚ùå **GPT classifica incorretamente** como "localiza√ß√£o" ao inv√©s de "pre√ßos"

### Por que o GPT errava?

- O GPT **n√£o recebia o hist√≥rico da conversa** no prompt
- Perguntas de **follow-up** (ex: "e o da fisioterapia?") **n√£o mantinham o t√≥pico** anterior
- Faltava detec√ß√£o de contexto conversacional

## ‚úÖ **Solu√ß√£o Implementada**

### 1. **Rastreamento de T√≥pico** (`lastTopic`)

Adicionei um sistema de rastreamento do t√≥pico atual da conversa:

```typescript
// Salva o t√≥pico quando detectado
this.context.userData.lastTopic = 'price'; // ou 'insurance', 'location', 'scheduling'
```

### 2. **Detec√ß√£o de Follow-Up Questions**

Criado detector de perguntas de continua√ß√£o:

```typescript
// Detecta padr√µes como "e o da...", "e a...", "e do..."
const isFollowUp = /^(e\s+)?((o|a)\s+)?(do|da|de|dos|das)\s+/.test(normalized.trim());
```

### 3. **Manuten√ß√£o de Contexto em Follow-Ups**

Quando uma pergunta √© follow-up + menciona procedimento, mant√©m o t√≥pico anterior:

```typescript
if (isFollowUp && hasProcIntent && lastTopic) {
  console.log(`üîß GPT_RESPONSE - Detected follow-up question, maintaining topic: ${lastTopic}`);
  if (lastTopic === 'price') {
    nextNodeId = connections.find(c => c.port === '1')?.targetId;
    // Mant√©m no fluxo de pre√ßos!
  }
}
```

### 4. **Hist√≥rico no Prompt do GPT**

O GPT agora recebe o hist√≥rico da conversa para melhor classifica√ß√£o:

```typescript
const historyContext = this.context.conversationHistory
  .slice(-4) // √öltimas 4 mensagens
  .map(h => `${h.role === 'user' ? 'Usu√°rio' : 'Bot'}: ${h.content}`)
  .join('\n');

const contextInfo = lastTopic 
  ? `\n\nContexto: O usu√°rio estava perguntando sobre ${lastTopic === 'price' ? 'valores/pre√ßos' : ...}` 
  : '';

const prompt = `${systemPrompt}\n\nHist√≥rico recente:\n${historyContext}${contextInfo}\n\n...`;
```

### 5. **Atualiza√ß√£o de T√≥pico Ap√≥s Classifica√ß√£o GPT**

O sistema atualiza o t√≥pico baseado na classifica√ß√£o:

```typescript
if (port === '1') this.context.userData.lastTopic = 'price';
else if (port === '2') this.context.userData.lastTopic = 'insurance';
else if (port === '3') this.context.userData.lastTopic = 'location';
// ...
```

## üéØ **Resultado Esperado**

Agora o fluxo funciona corretamente:

```
USER: qual valor da acupuntura?
BOT: üíâ Acupuntura - R$ 180,00/sess√£o ‚úÖ
(lastTopic = 'price')

USER: e o da fisioterapia?
(isFollowUp = true, mant√©m lastTopic = 'price')
BOT: üí∞ Fisioterapia - R$ 150,00/sess√£o ‚úÖ
(lastTopic = 'price')

USER: qual o hor√°rio?
(n√£o √© follow-up, detecta intent 'location')
BOT: üìç Hor√°rios de Atendimento ‚úÖ
(lastTopic = 'location')
```

## üìÅ **Arquivos Modificados**

- `src/services/workflowEngine.ts` - Fun√ß√£o `executeGPTResponseNode()`
  - Linhas ~521-650: L√≥gica completa de classifica√ß√£o com contexto
  - **Modelo atualizado:** gpt-3.5-turbo ‚Üí **gpt-4o** (melhor precis√£o)

## üß™ **Como Testar**

1. Inicie uma conversa e escolha uma unidade
2. Pergunte: "qual valor da acupuntura?"
3. Ap√≥s a resposta, pergunte: "e o da fisioterapia?"
4. O bot deve responder com os **pre√ßos da fisioterapia**, n√£o com localiza√ß√£o

## üìù **Notas T√©cnicas**

- O `lastTopic` √© salvo em `context.userData` e persiste no banco via `workflowContext`
- O workflow JSON j√° tinha as conex√µes corretas (`tmpl_prices` ‚Üí `gpt_classifier`)
- O problema era puramente na l√≥gica de classifica√ß√£o do GPT
- A solu√ß√£o √© **backward-compatible** e n√£o quebra fluxos existentes

## üöÄ **Upgrade GPT-4o**

Al√©m das corre√ß√µes de contexto, o sistema foi atualizado para usar **GPT-4o**:

- **Modelo anterior:** gpt-3.5-turbo
- **Modelo atual:** gpt-4o
- **Benef√≠cio:** Classifica√ß√£o de inten√ß√µes muito mais precisa
- **Impacto:** Redu√ß√£o significativa de erros em follow-up questions
- **Documenta√ß√£o:** Ver `GPT4O_UPGRADE.md` para detalhes completos

---

**Data da Corre√ß√£o:** 24/11/2025  
**Desenvolvedor:** AI Assistant  
**Vers√£o:** 2.0.0 (com GPT-4o)

