import OpenAI from 'openai'
import { conversationContextService, type EnhancedContext } from './conversationContext.js'
import { prismaClinicDataService } from './prismaClinicDataService.js'

/**
 * Resposta estruturada da IA conversacional
 */
export interface ConversationalResponse {
    message: string
    intent: 'INFORMACAO' | 'AGENDAR' | 'CANCELAR' | 'REAGENDAR' | 'ATRASO' | 'RECLAMACAO' | 'CONVERSA_LIVRE'
    sentiment: 'positive' | 'neutral' | 'negative'
    action: 'continue' | 'transfer_human' | 'start_workflow' | 'collect_data'
    confidence: number
    entities: {
        procedimento?: string
        convenio?: string
        clinica?: string
        data?: string
        horario?: string
    }
    suggestedNextSteps: string[]
}

/**
 * Servi√ßo de IA Conversacional Pura
 * 
 * Conversa naturalmente como ChatGPT, mas com conhecimento espec√≠fico da cl√≠nica
 */
export class ConversationalAIService {
    private openai: OpenAI
    private model: string
    private timeout: number

    constructor(apiKey: string, model = 'gpt-4o', timeout = 20000) {
        console.log('ü§ñ ConversationalAIService constructor - API Key present:', !!apiKey)
        if (!apiKey) {
            console.error('‚ùå No OpenAI API key provided to ConversationalAIService')
        }
        this.openai = new OpenAI({ apiKey })
        this.model = model
        this.timeout = timeout
    }

    /**
     * Gera resposta conversacional natural
     */
    async generateResponse(
        message: string,
        conversationId: string,
        phone: string
    ): Promise<ConversationalResponse> {
        console.log(`ü§ñ Gerando resposta conversacional para: "${message}"`)

        try {
            // 1. Buscar contexto enriquecido
            const context = await conversationContextService.buildContext(conversationId, phone)

            console.log(`üîç CONTEXTO COMPLETO:`, {
                totalConversations: context.history.totalConversations,
                recentMessages: context.history.recent.length,
                patientName: context.patient.name,
                isFirstContact: context.history.totalConversations === 0
            })

            // 2. Buscar dados da cl√≠nica OU todos os procedimentos
            let clinicData = await this.getClinicData(context.currentState.selectedClinic)

            // Se n√£o h√° cl√≠nica selecionada, buscar TODOS os procedimentos
            if (!clinicData) {
                console.log(`üì¶ Nenhuma cl√≠nica selecionada, buscando TODOS os procedimentos...`)
                const allProcedures = await prismaClinicDataService.getProcedures()
                const allInsurances = await prismaClinicDataService.getInsuranceCompanies()

                clinicData = {
                    name: 'Cl√≠nicas IAAM',
                    address: 'Vieiralves e S√£o Jos√©',
                    phone: '(92) 3000-0000',
                    procedures: allProcedures.map(p => ({
                        id: p.id,
                        name: p.name,
                        description: p.description,
                        price: p.basePrice, // Mapear basePrice para price
                        hasPackage: p.packages && p.packages.length > 0,
                        packages: p.packages,
                        duration: p.duration,
                        requiresEvaluation: p.requiresEvaluation,
                        importantInfo: '' // Campo n√£o existe em Procedure base
                    })),
                    insurances: allInsurances.map(i => ({
                        id: i.id,
                        name: i.name,
                        displayName: i.displayName,
                        discount: false, // Campo n√£o existe em Insurance base
                        discountPercentage: 0
                    }))
                }

                console.log(`‚úÖ Carregados ${allProcedures.length} procedimentos`)
            }

            // 3. Construir system prompt RICO (agora din√¢mico do banco)
            const systemPrompt = await this.buildRichSystemPrompt(context, clinicData)

            // 4. Preparar hist√≥rico de mensagens (√∫ltimas 20 para manter contexto)
            const historyMessages = context.history.recent.slice(-20).map(h => ({
                role: h.role as 'user' | 'assistant',
                content: h.content
            }))

            console.log(`üìú Hist√≥rico de ${historyMessages.length} mensagens inclu√≠do no contexto`)
            console.log(`üìú √öLTIMAS 5 MENSAGENS DO HIST√ìRICO:`)
            historyMessages.slice(-5).forEach((msg, i) => {
                console.log(`  ${i + 1}. [${msg.role}]: "${msg.content.substring(0, 100)}${msg.content.length > 100 ? '...' : ''}"`)
            })
            console.log(`üìù MENSAGEM ATUAL DO USU√ÅRIO: "${message}"`)

            // 5. Gerar resposta com GPT-4o (JSON mode) - COM RETRY para rate limits
            console.log(`üîë Usando modelo: ${this.model}`)
            console.log(`üîë API Key configurada: ${this.openai.apiKey ? 'SIM (oculta)' : 'N√ÉO'}`)
            console.log(`üì§ Enviando requisi√ß√£o para OpenAI...`)
            
            // ‚úÖ Retry logic para rate limits (429)
            let completion
            let retries = 0
            const maxRetries = 3
            const baseDelay = 2000 // 2 segundos
            
            while (retries <= maxRetries) {
                try {
                    completion = await this.openai.chat.completions.create({
                        model: this.model,
                        messages: [
                            { role: 'system', content: systemPrompt },
                            ...historyMessages,
                            { role: 'user', content: message }
                        ],
                        temperature: 0.7,
                        max_tokens: 1000,
                        response_format: { type: 'json_object' }
                    })
                    break // Sucesso, sair do loop
                } catch (error: any) {
                    // Se for rate limit (429) e ainda temos tentativas, fazer retry
                    if (error.status === 429 && retries < maxRetries) {
                        const delay = baseDelay * Math.pow(2, retries) // Backoff exponencial: 2s, 4s, 8s
                        console.log(`‚è≥ Rate limit detectado (429). Aguardando ${delay}ms antes de tentar novamente... (tentativa ${retries + 1}/${maxRetries})`)
                        await new Promise(resolve => setTimeout(resolve, delay))
                        retries++
                        continue
                    }
                    // Se n√£o for rate limit ou esgotamos tentativas, lan√ßar erro
                    throw error
                }
            }

            console.log(`üì• Resposta recebida da OpenAI`)
            const responseText = completion.choices[0]?.message?.content || '{}'
            console.log(`üìù Resposta bruta (primeiros 200 caracteres): ${responseText.substring(0, 200)}`)
            
            const response = JSON.parse(responseText)
            console.log(`‚úÖ JSON parseado com sucesso`)

            console.log(`‚úÖ Resposta gerada:`, {
                intent: response.intent,
                action: response.action,
                confidence: response.confidence,
                entities: response.entities
            })

            // ‚úÖ REMOVIDO: Valida√ß√µes bugadas que impediam o usu√°rio de mudar de assunto
            // O usu√°rio TEM DIREITO de perguntar sobre acupuntura depois de fisioterapia!

            return {
                message: response.message || 'Desculpe, n√£o consegui processar sua mensagem.',
                intent: response.intent || 'CONVERSA_LIVRE',
                sentiment: response.sentiment || 'neutral',
                action: response.action || 'continue',
                confidence: response.confidence || 0.5,
                entities: response.entities || {},
                suggestedNextSteps: response.suggestedNextSteps || []
            }

        } catch (error) {
            console.error('‚ùå Erro ao gerar resposta conversacional:', error)
            console.error('‚ùå Erro detalhado:', error instanceof Error ? error.message : String(error))
            console.error('‚ùå Stack trace:', error instanceof Error ? error.stack : 'N/A')
            
            // Verificar tipo espec√≠fico de erro
            if (error && typeof error === 'object' && 'status' in error) {
                const status = (error as any).status
                const code = (error as any).code
                
                if (status === 429 || code === 'insufficient_quota' || code === 'rate_limit_exceeded') {
                    console.error('‚ùå ERRO DE RATE LIMIT/QUOTA:')
                    console.error('   ‚Üí Status: 429')
                    console.error('   ‚Üí C√≥digo:', code)
                    console.error('   ‚Üí Poss√≠veis causas:')
                    console.error('      1. Limite de requisi√ß√µes por minuto/hora atingido')
                    console.error('      2. Quota do projeto/organiza√ß√£o esgotada')
                    console.error('      3. Chave da API n√£o associada ao projeto com cr√©ditos')
                    console.error('   ‚Üí Solu√ß√µes:')
                    console.error('      ‚Ä¢ Aguarde alguns minutos e tente novamente')
                    console.error('      ‚Ä¢ Verifique billing: https://platform.openai.com/settings/organization/billing')
                    console.error('      ‚Ä¢ Use modelo mais barato (gpt-3.5-turbo) temporariamente')
                } else if (status === 401) {
                    console.error('‚ùå ERRO DE AUTENTICA√á√ÉO: Chave da API OpenAI inv√°lida ou n√£o configurada')
                    console.error('‚ùå Verifique a vari√°vel de ambiente OPENAI_API_KEY')
                } else if (status === 404) {
                    console.error('‚ùå ERRO DE MODELO: Modelo GPT n√£o encontrado ou indispon√≠vel')
                    console.error(`   ‚Üí Modelo tentado: ${this.model}`)
                    console.error('   ‚Üí Tente usar: gpt-3.5-turbo ou gpt-4-turbo')
                }
            } else if (error instanceof Error) {
                if (error.message?.includes('API key') || error.message?.includes('authentication') || error.message?.includes('401')) {
                    console.error('‚ùå ERRO DE AUTENTICA√á√ÉO: Chave da API OpenAI inv√°lida ou n√£o configurada')
                    console.error('‚ùå Verifique a vari√°vel de ambiente OPENAI_API_KEY')
                }
                if (error.message?.includes('rate limit') || error.message?.includes('429')) {
                    console.error('‚ùå ERRO DE RATE LIMIT: Limite de requisi√ß√µes atingido')
                }
                if (error.message?.includes('model') || error.message?.includes('404')) {
                    console.error('‚ùå ERRO DE MODELO: Modelo GPT n√£o encontrado ou indispon√≠vel')
                }
            }

            // Fallback response
            return {
                message: 'Desculpe, estou com dificuldades para processar sua mensagem. Posso transferir voc√™ para um atendente humano?',
                intent: 'CONVERSA_LIVRE',
                sentiment: 'neutral',
                action: 'transfer_human',
                confidence: 0.3,
                entities: {},
                suggestedNextSteps: ['Falar com atendente humano']
            }
        }
    }

    /**
     * Constr√≥i system prompt rico com contexto e dados da cl√≠nica
     * Agora usa configura√ß√£o din√¢mica do banco de dados
     */
    private async buildRichSystemPrompt(context: EnhancedContext, clinicData: any): Promise<string> {
        // Importar dinamicamente para evitar circular dependency
        const { aiConfigurationService } = await import('./aiConfigurationService.js')
        return await aiConfigurationService.buildDynamicPrompt(context, clinicData)
    }

    /**
     * Busca dados da cl√≠nica selecionada
     */
    private async getClinicData(clinicCode?: string) {
        if (!clinicCode) {
            return null
        }

        try {
            const clinic = await prismaClinicDataService.getClinicByName(clinicCode)
            if (!clinic) return null

            const procedures = await prismaClinicDataService.getProceduresByClinic(clinicCode)
            const insurances = await prismaClinicDataService.getInsurancesByClinic(clinicCode)

            return {
                name: clinic.displayName,
                address: clinic.address,
                phone: clinic.phone,
                procedures,
                insurances
            }
        } catch (error) {
            console.error('Erro ao buscar dados da cl√≠nica:', error)
            return null
        }
    }
}

// Exportar singleton
let instance: ConversationalAIService | null = null

export const conversationalAI = {
    getInstance(): ConversationalAIService {
        if (!instance) {
            console.log('ü§ñ Creating ConversationalAIService instance...')
            instance = new ConversationalAIService(
                process.env.OPENAI_API_KEY || '',
                process.env.OPENAI_MODEL || 'gpt-4o',
                Number(process.env.OPENAI_TIMEOUT) || 20000
            )
        }
        return instance
    }
}
