#!/usr/bin/env tsx
/**
 * Script para testar o modelo gpt-5-nano
 * Testa disponibilidade e qualidade comparando com gpt-3.5-turbo
 */

import OpenAI from 'openai';
import * as dotenv from 'dotenv';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// Load env from root
dotenv.config({ path: join(__dirname, '..', '.env') });

const apiKey = process.env.OPENAI_API_KEY;

if (!apiKey) {
  console.error('‚ùå OPENAI_API_KEY n√£o encontrada no .env');
  process.exit(1);
}

const client = new OpenAI({ apiKey });

// Mensagens de teste reais do sistema
const testMessages = [
  'Quanto custa fisioterapia?',
  'Voc√™s aceitam conv√™nio Bradesco?',
  'Qual o endere√ßo da cl√≠nica?',
  'Quero agendar uma consulta',
  'Bom dia! Gostaria de informa√ß√µes sobre acupuntura',
  'Preciso fazer fisioterapia p√©lvica, tem vaga?'
];

async function testModel(model: string, message: string): Promise<{ response: string; time: number; tokens: number; error?: string }> {
  const start = Date.now();
  
  try {
    // gpt-5-nano usa max_completion_tokens ao inv√©s de max_tokens
    const isGpt5Nano = model === 'gpt-5-nano';
    
    const params: any = {
      model,
      messages: [
        {
          role: 'system',
          content: 'Voc√™ √© um assistente virtual de uma cl√≠nica de fisioterapia. Responda de forma breve e √∫til.'
        },
        { role: 'user', content: message }
      ]
    };

    // gpt-5-nano tem restri√ß√µes espec√≠ficas
    if (isGpt5Nano) {
      params.max_completion_tokens = 150;
      // temperature n√£o √© suportado - usa default (1)
    } else {
      params.max_tokens = 150;
      params.temperature = 0.7;
    }

    const completion = await client.chat.completions.create(params);

    const time = Date.now() - start;
    const response = completion.choices[0]?.message?.content || '';
    const tokens = completion.usage?.total_tokens || 0;

    return { response, time, tokens };
  } catch (error: any) {
    const time = Date.now() - start;
    return { 
      response: '', 
      time, 
      tokens: 0,
      error: error.message || String(error)
    };
  }
}

async function runTests() {
  console.log('üß™ Testando disponibilidade e qualidade do gpt-5-nano\n');
  console.log('=' .repeat(80));
  
  const models = ['gpt-5-nano', 'gpt-3.5-turbo', 'gpt-4o-mini'];
  const results: Record<string, any[]> = {};

  for (const model of models) {
    console.log(`\nüìä Testando modelo: ${model}`);
    console.log('-'.repeat(80));
    
    results[model] = [];

    for (let i = 0; i < testMessages.length; i++) {
      const message = testMessages[i];
      console.log(`\n${i + 1}. Mensagem: "${message}"`);
      
      const result = await testModel(model, message);
      results[model].push(result);

      if (result.error) {
        console.log(`   ‚ùå ERRO: ${result.error}`);
      } else {
        console.log(`   ‚úÖ Tempo: ${result.time}ms | Tokens: ${result.tokens}`);
        console.log(`   üìù Resposta: ${result.response.substring(0, 100)}${result.response.length > 100 ? '...' : ''}`);
      }
    }
  }

  // An√°lise comparativa
  console.log('\n\n' + '='.repeat(80));
  console.log('üìä AN√ÅLISE COMPARATIVA');
  console.log('='.repeat(80));

  for (const model of models) {
    const modelResults = results[model];
    const successful = modelResults.filter(r => !r.error);
    const failed = modelResults.filter(r => r.error);

    if (successful.length === 0) {
      console.log(`\n‚ùå ${model}: MODELO N√ÉO DISPON√çVEL ou ERRO EM TODOS OS TESTES`);
      if (failed.length > 0) {
        console.log(`   Erro t√≠pico: ${failed[0].error}`);
      }
      continue;
    }

    const avgTime = successful.reduce((acc, r) => acc + r.time, 0) / successful.length;
    const avgTokens = successful.reduce((acc, r) => acc + r.tokens, 0) / successful.length;
    const totalTokens = successful.reduce((acc, r) => acc + r.tokens, 0);

    // Calcular custo baseado nos pre√ßos do plano
    const costs: Record<string, { input: number; output: number }> = {
      'gpt-5-nano': { input: 0.05, output: 0.40 },
      'gpt-3.5-turbo': { input: 0.50, output: 1.50 },
      'gpt-4o-mini': { input: 0.15, output: 0.60 }
    };

    const modelCost = costs[model] || costs['gpt-3.5-turbo'];
    // Estimativa: ~30% input, 70% output
    const estimatedCost = (totalTokens * 0.3 * modelCost.input / 1000000) + (totalTokens * 0.7 * modelCost.output / 1000000);

    console.log(`\n‚úÖ ${model}:`);
    console.log(`   Sucessos: ${successful.length}/${modelResults.length}`);
    console.log(`   Tempo m√©dio: ${avgTime.toFixed(0)}ms`);
    console.log(`   Tokens m√©dios: ${avgTokens.toFixed(0)}`);
    console.log(`   Tokens totais: ${totalTokens}`);
    console.log(`   Custo estimado: $${estimatedCost.toFixed(6)} (${testMessages.length} mensagens)`);
    console.log(`   Custo por 1000 msgs: $${(estimatedCost * 1000 / testMessages.length).toFixed(2)}`);
  }

  // Recomenda√ß√£o final
  console.log('\n' + '='.repeat(80));
  console.log('üéØ RECOMENDA√á√ÉO');
  console.log('='.repeat(80));

  const gpt5Available = results['gpt-5-nano'].filter(r => !r.error).length > 0;
  const gpt35Available = results['gpt-3.5-turbo'].filter(r => !r.error).length > 0;

  if (gpt5Available) {
    const gpt5Results = results['gpt-5-nano'].filter(r => !r.error);
    const gpt35Results = results['gpt-3.5-turbo'].filter(r => !r.error);

    const gpt5AvgTime = gpt5Results.reduce((acc, r) => acc + r.time, 0) / gpt5Results.length;
    const gpt35AvgTime = gpt35Results.reduce((acc, r) => acc + r.time, 0) / gpt35Results.length;

    const speedDiff = ((gpt5AvgTime - gpt35AvgTime) / gpt35AvgTime * 100).toFixed(0);

    console.log(`\n‚úÖ gpt-5-nano est√° DISPON√çVEL e funcional!`);
    console.log(`\nüìä Compara√ß√£o com gpt-3.5-turbo:`);
    console.log(`   Velocidade: ${speedDiff}% ${parseInt(speedDiff) > 0 ? 'mais lento' : 'mais r√°pido'}`);
    console.log(`   Custo: ~85% mais barato`);
    console.log(`\nüéâ RECOMENDA√á√ÉO: Migrar para gpt-5-nano!`);
    console.log(`\nüìù Pr√≥ximos passos:`);
    console.log(`   1. Atualizar .env com gpt-5-nano`);
    console.log(`   2. Testar em ambiente de staging`);
    console.log(`   3. Deploy em produ√ß√£o`);
  } else if (gpt35Available) {
    console.log(`\n‚ö†Ô∏è  gpt-5-nano N√ÉO est√° dispon√≠vel ou teve erros`);
    console.log(`\nüí° ALTERNATIVA: Usar gpt-4o-mini (j√° mais barato que gpt-3.5-turbo)`);
    console.log(`\nüìù Pr√≥ximos passos:`);
    console.log(`   1. Verificar se gpt-5-nano estar√° dispon√≠vel em breve`);
    console.log(`   2. Migrar para gpt-4o-mini como solu√ß√£o intermedi√°ria`);
    console.log(`   3. Implementar outras otimiza√ß√µes (cache, fallbacks)`);
  } else {
    console.log(`\n‚ùå ERRO: Nenhum modelo funcionou. Verificar API key e conectividade.`);
  }

  console.log('\n' + '='.repeat(80));
}

// Executar testes
runTests().catch(error => {
  console.error('‚ùå Erro ao executar testes:', error);
  process.exit(1);
});
