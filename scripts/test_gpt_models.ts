import OpenAI from 'openai'
import dotenv from 'dotenv'

dotenv.config()

const apiKey = process.env.OPENAI_API_KEY

if (!apiKey) {
  console.error('âŒ OPENAI_API_KEY nÃ£o configurada no .env')
  process.exit(1)
}

const client = new OpenAI({ apiKey })

// Modelos configurados
const classificationModel = process.env.OPENAI_CLASSIFICATION_MODEL || 'gpt-4o-mini'
const responseModel = process.env.OPENAI_RESPONSE_MODEL || 'gpt-4o'

console.log('ğŸ§ª Testando Modelos GPT\n')
console.log('ğŸ“‹ ConfiguraÃ§Ã£o:')
console.log(`   ClassificaÃ§Ã£o: ${classificationModel}`)
console.log(`   Respostas: ${responseModel}\n`)

async function testClassificationModel() {
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
  console.log('ğŸ“Š TESTE 1: Modelo de ClassificaÃ§Ã£o')
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n')
  
  const testMessages = [
    'tenho encaminhamento pra fisioterapia',
    'quanto custa o rpg?',
    'quero agendar',
    'vocÃªs atendem bradesco?'
  ]
  
  for (const message of testMessages) {
    console.log(`ğŸ’¬ Testando: "${message}"`)
    
    const startTime = Date.now()
    
    try {
      const completion = await client.chat.completions.create({
        model: classificationModel,
        messages: [
          {
            role: 'system',
            content: 'VocÃª Ã© um classificador de intenÃ§Ã£o. Responda APENAS com JSON: {"intent_port":"1-6","brief":"resposta Ãºtil","confidence":0.0-1.0}'
          },
          {
            role: 'user',
            content: `Classifique esta mensagem: "${message}"`
          }
        ],
        temperature: 0.3,
        max_tokens: 150
      })
      
      const elapsed = Date.now() - startTime
      const response = completion.choices[0]?.message?.content || ''
      
      console.log(`   âœ… Modelo: ${classificationModel}`)
      console.log(`   â±ï¸  Tempo: ${elapsed}ms`)
      console.log(`   ğŸ“ Resposta: ${response.substring(0, 100)}...`)
      console.log(`   ğŸ’° Tokens: ${completion.usage?.total_tokens || 'N/A'}`)
      console.log('')
    } catch (error: any) {
      console.log(`   âŒ Erro: ${error.message}`)
      console.log('')
    }
  }
}

async function testResponseModel() {
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
  console.log('ğŸ’¬ TESTE 2: Modelo de Resposta Complexa')
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n')
  
  const testMessages = [
    {
      message: 'tenho encaminhamento pra fisioterapia',
      context: 'ClÃ­nica: Unidade Vieiralves\nProcedimentos: Fisioterapia OrtopÃ©dica (R$ 90), RPG (R$ 120), Acupuntura (R$ 180)'
    },
    {
      message: 'me explique o que Ã© RPG',
      context: 'RPG Ã© um mÃ©todo de reequilÃ­brio postural que atua em cadeias musculares.'
    }
  ]
  
  for (const test of testMessages) {
    console.log(`ğŸ’¬ Testando: "${test.message}"`)
    
    const startTime = Date.now()
    
    try {
      const completion = await client.chat.completions.create({
        model: responseModel,
        messages: [
          {
            role: 'system',
            content: `VocÃª Ã© um assistente de clÃ­nica de fisioterapia. Seja conversacional e Ãºtil.\n\nContexto:\n${test.context}`
          },
          {
            role: 'user',
            content: test.message
          }
        ],
        temperature: 0.7,
        max_tokens: 300
      })
      
      const elapsed = Date.now() - startTime
      const response = completion.choices[0]?.message?.content || ''
      
      console.log(`   âœ… Modelo: ${responseModel}`)
      console.log(`   â±ï¸  Tempo: ${elapsed}ms`)
      console.log(`   ğŸ“ Resposta: ${response.substring(0, 150)}...`)
      console.log(`   ğŸ’° Tokens: ${completion.usage?.total_tokens || 'N/A'}`)
      console.log('')
    } catch (error: any) {
      console.log(`   âŒ Erro: ${error.message}`)
      console.log('')
    }
  }
}

async function testModelComparison() {
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
  console.log('âš–ï¸  TESTE 3: ComparaÃ§Ã£o de Modelos')
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n')
  
  const testMessage = 'tenho encaminhamento pra fisioterapia'
  
  console.log(`ğŸ’¬ Mensagem: "${testMessage}"\n`)
  
  // Testar com gpt-4o-mini
  console.log('ğŸ“Š Testando com gpt-4o-mini:')
  const start1 = Date.now()
  try {
    const result1 = await client.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: 'Seja Ãºtil e conversacional.' },
        { role: 'user', content: testMessage }
      ],
      temperature: 0.7,
      max_tokens: 200
    })
    const time1 = Date.now() - start1
    console.log(`   â±ï¸  Tempo: ${time1}ms`)
    console.log(`   ğŸ“ Resposta: ${result1.choices[0]?.message?.content?.substring(0, 100)}...`)
    console.log(`   ğŸ’° Tokens: ${result1.usage?.total_tokens}`)
  } catch (error: any) {
    console.log(`   âŒ Erro: ${error.message}`)
  }
  
  console.log('')
  
  // Testar com gpt-4o
  console.log('ğŸ“Š Testando com gpt-4o:')
  const start2 = Date.now()
  try {
    const result2 = await client.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: 'Seja Ãºtil e conversacional.' },
        { role: 'user', content: testMessage }
      ],
      temperature: 0.7,
      max_tokens: 200
    })
    const time2 = Date.now() - start2
    console.log(`   â±ï¸  Tempo: ${time2}ms`)
    console.log(`   ğŸ“ Resposta: ${result2.choices[0]?.message?.content?.substring(0, 100)}...`)
    console.log(`   ğŸ’° Tokens: ${result2.usage?.total_tokens}`)
  } catch (error: any) {
    console.log(`   âŒ Erro: ${error.message}`)
  }
  
  console.log('')
}

async function runAllTests() {
  try {
    await testClassificationModel()
    await testResponseModel()
    await testModelComparison()
    
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    console.log('âœ… Todos os testes concluÃ­dos!')
    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n')
    
    console.log('ğŸ“Š Resumo:')
    console.log(`   âœ… Modelo de classificaÃ§Ã£o: ${classificationModel}`)
    console.log(`   âœ… Modelo de resposta: ${responseModel}`)
    console.log('\nğŸ’¡ Dica: Verifique os logs acima para confirmar que cada modelo estÃ¡ sendo usado corretamente!')
    
  } catch (error) {
    console.error('âŒ Erro nos testes:', error)
    process.exit(1)
  }
}

runAllTests()

