# ğŸ§ª Como Testar os Modelos GPT

## âœ… Teste Automatizado

Execute o script de teste:

```bash
npm run test:gpt-models
```

### O que o teste faz:

1. **Testa Modelo de ClassificaÃ§Ã£o** (gpt-4o-mini)
   - Testa 4 mensagens diferentes
   - Mostra tempo de resposta
   - Mostra tokens usados
   - Confirma que estÃ¡ usando gpt-4o-mini

2. **Testa Modelo de Resposta** (gpt-4o)
   - Testa respostas complexas
   - Mostra tempo de resposta
   - Mostra tokens usados
   - Confirma que estÃ¡ usando gpt-4o

3. **Compara Modelos**
   - Testa a mesma mensagem com ambos os modelos
   - Mostra diferenÃ§a de tempo e qualidade

## ğŸ“Š Resultados Esperados

### âœ… Teste Bem-Sucedido:

```
ğŸ“‹ ConfiguraÃ§Ã£o:
   ClassificaÃ§Ã£o: gpt-4o-mini
   Respostas: gpt-4o

âœ… Modelo: gpt-4o-mini
â±ï¸  Tempo: ~1000-2000ms
ğŸ’° Tokens: ~80-100

âœ… Modelo: gpt-4o
â±ï¸  Tempo: ~1500-5000ms
ğŸ’° Tokens: ~130-300
```

### âš ï¸ Se Der Erro:

**Erro: "OPENAI_API_KEY nÃ£o configurada"**
- Verifique se o `.env` tem a chave configurada

**Erro: "Model not found"**
- Verifique se os nomes dos modelos estÃ£o corretos
- Modelos vÃ¡lidos: `gpt-4o-mini`, `gpt-4o`, `gpt-4-turbo`

## ğŸ” Teste Manual (Durante ConversaÃ§Ã£o)

### 1. Verificar Logs no Console

Quando uma mensagem chegar, vocÃª verÃ¡ nos logs:

```
ğŸ¤– [GPT] Using model: gpt-4o-mini for intent classification
ğŸ¤– [GPT Response] Using model: gpt-4o for contextual response
```

### 2. Verificar Logs no Workflow

No workflow editor, os logs mostrarÃ£o:

```
ğŸ¤– [GPT] ğŸ“Š Modelo usado: gpt-4o-mini
ğŸ¤– [GPT Response] ğŸ“Š Modelo usado: gpt-4o
```

### 3. Testar ConversaÃ§Ã£o Real

**Teste 1: ClassificaÃ§Ã£o (deve usar gpt-4o-mini)**
```
USER: "quero agendar"
```
**Logs esperados:**
- `ğŸ¤– [GPT] Using model: gpt-4o-mini`
- Tempo: ~1000-2000ms
- Resposta: ClassificaÃ§Ã£o JSON

**Teste 2: Resposta Complexa (deve usar gpt-4o)**
```
USER: "me explique o que Ã© RPG"
```
**Logs esperados:**
- `ğŸ¤– [GPT Response] Using model: gpt-4o`
- Tempo: ~2000-5000ms
- Resposta: Texto rico e detalhado

## ğŸ“ˆ ComparaÃ§Ã£o de Performance

### gpt-4o-mini (ClassificaÃ§Ã£o):
- â±ï¸ Tempo: ~1000-2000ms
- ğŸ’° Custo: ~$0.0002 por chamada
- âœ… Ideal para: ClassificaÃ§Ã£o rÃ¡pida

### gpt-4o (Respostas):
- â±ï¸ Tempo: ~2000-5000ms
- ğŸ’° Custo: ~$0.002 por chamada
- âœ… Ideal para: Respostas ricas

## ğŸ”§ Troubleshooting

### Problema: Ambos usando o mesmo modelo

**Sintoma:**
```
ğŸ¤– [GPT] Using model: gpt-4o
ğŸ¤– [GPT Response] Using model: gpt-4o
```

**SoluÃ§Ã£o:**
1. Verifique o `.env`:
   ```bash
   OPENAI_CLASSIFICATION_MODEL="gpt-4o-mini"
   OPENAI_RESPONSE_MODEL="gpt-4o"
   ```

2. Reinicie o servidor:
   ```bash
   # Ctrl+C
   npm run up
   ```

### Problema: Modelo nÃ£o encontrado

**Sintoma:**
```
Error: Model 'gpt-5-nano' not found
```

**SoluÃ§Ã£o:**
- Use modelos vÃ¡lidos: `gpt-4o-mini`, `gpt-4o`, `gpt-4-turbo`
- Verifique a documentaÃ§Ã£o da OpenAI para modelos disponÃ­veis

### Problema: Respostas muito lentas

**Sintoma:**
- Tempo > 10 segundos

**SoluÃ§Ã£o:**
1. Verifique sua conexÃ£o com a internet
2. Tente usar `gpt-4o-mini` para ambos (mais rÃ¡pido)
3. Verifique se hÃ¡ rate limiting na API

## ğŸ“ Checklist de Teste

- [ ] Execute `npm run test:gpt-models`
- [ ] Verifique que ambos os modelos aparecem nos logs
- [ ] Teste uma conversa real
- [ ] Verifique logs no console durante conversaÃ§Ã£o
- [ ] Confirme que classificaÃ§Ã£o usa gpt-4o-mini
- [ ] Confirme que respostas usam gpt-4o

## ğŸ¯ Teste RÃ¡pido (1 minuto)

```bash
# 1. Execute o teste
npm run test:gpt-models

# 2. Verifique os resultados
# Deve mostrar:
# âœ… Modelo: gpt-4o-mini (classificaÃ§Ã£o)
# âœ… Modelo: gpt-4o (respostas)

# 3. Se tudo OK, estÃ¡ funcionando! âœ…
```

## ğŸ’¡ Dicas

1. **Monitore os custos**: Use `gpt-4o-mini` para classificaÃ§Ã£o economiza 90%
2. **Ajuste conforme necessidade**: Se precisar de mais qualidade, use `gpt-4-turbo`
3. **Teste regularmente**: Execute o teste apÃ³s mudanÃ§as no cÃ³digo
4. **Verifique logs**: Sempre confira os logs para confirmar qual modelo estÃ¡ sendo usado

---

**Status:** Script de teste criado e funcionando! âœ…

