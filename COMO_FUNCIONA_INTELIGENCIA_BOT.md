# ğŸ¤– Como Funciona a InteligÃªncia do Bot

## ğŸ“‹ VisÃ£o Geral

A inteligÃªncia do bot estÃ¡ **100% configurÃ¡vel via banco de dados**, mas hÃ¡ um prompt base **hardcoded** que Ã© construÃ­do dinamicamente. Toda a fluidez vem da combinaÃ§Ã£o de:

1. **Prompt base** (hardcoded em `aiConfigurationService.ts`)
2. **ConfiguraÃ§Ã£o do banco** (tabela `AIConfiguration`)
3. **Contexto dinÃ¢mico** (histÃ³rico, paciente, agendamentos)
4. **Exemplos de conversas** (few-shot learning do banco)
5. **Regras de transferÃªncia** (do banco)

---

## ğŸ” Arquitetura da IA

### Fluxo de Processamento

```
Mensagem do Paciente
    â†“
conversationalAI.generateResponse()
    â†“
1. Busca contexto (conversationContextService)
   - HistÃ³rico de mensagens
   - Dados do paciente
   - Agendamentos anteriores
   - MemÃ³rias de longo prazo
    â†“
2. Busca dados da clÃ­nica (prismaClinicDataService)
   - Procedimentos disponÃ­veis
   - ConvÃªnios aceitos
   - PreÃ§os e pacotes
    â†“
3. ConstrÃ³i prompt dinÃ¢mico (aiConfigurationService.buildDynamicPrompt)
   - Prompt base do banco
   - Contexto do paciente
   - Dados da clÃ­nica
   - Exemplos de conversas
   - Regras de negÃ³cio
    â†“
4. Chama GPT-4o (OpenAI API)
   - Model: gpt-4o
   - Temperature: 0.7
   - Max tokens: 1000
   - Response format: JSON
    â†“
5. Retorna resposta estruturada
   - message: texto da resposta
   - intent: intenÃ§Ã£o detectada
   - sentiment: sentimento
   - action: aÃ§Ã£o a tomar
   - entities: dados extraÃ­dos
```

---

## ğŸ“ Arquivos Principais

### 1. `api/services/conversationalAI.ts`
- **FunÃ§Ã£o**: ServiÃ§o principal de IA conversacional
- **Responsabilidade**: Gerar respostas usando GPT-4o
- **DependÃªncias**: 
  - `conversationContextService` (contexto)
  - `prismaClinicDataService` (dados da clÃ­nica)
  - `aiConfigurationService` (prompt dinÃ¢mico)

### 2. `api/services/aiConfigurationService.ts`
- **FunÃ§Ã£o**: ConstrÃ³i o prompt dinÃ¢mico
- **CÃ³digo Hardcoded**: âš ï¸ **AQUI ESTÃ O PROMPT PRINCIPAL!**
- **LocalizaÃ§Ã£o**: Linhas 102-489
- **O que faz**:
  - Busca configuraÃ§Ã£o ativa do banco (`AIConfiguration`)
  - Adiciona contexto do paciente
  - Adiciona dados da clÃ­nica
  - Adiciona exemplos (few-shot learning)
  - Adiciona regras de transferÃªncia
  - Formata tudo em um prompt gigante

### 3. `api/services/conversationContext.ts`
- **FunÃ§Ã£o**: ConstrÃ³i contexto enriquecido
- **O que inclui**:
  - Dados do paciente
  - HistÃ³rico de conversas
  - Agendamentos (passados e futuros)
  - MemÃ³rias de longo prazo
  - PreferÃªncias aprendidas

### 4. `api/services/intelligentRouter.ts`
- **FunÃ§Ã£o**: Decide o que fazer com a resposta da IA
- **AÃ§Ãµes**:
  - `continue`: Continua conversando
  - `collect_data`: Coleta dados do cadastro
  - `transfer_human`: Transfere para atendente

---

## ğŸ¯ Onde EstÃ¡ o CÃ³digo Hardcoded

### Prompt Principal (Hardcoded)

**Arquivo**: `api/services/aiConfigurationService.ts`  
**MÃ©todo**: `buildDynamicPrompt()`  
**Linhas**: 102-489

Este prompt contÃ©m:

1. **Personalidade da Maria** (linhas 104-157)
   - Quem ela Ã©
   - Tom de voz
   - Estilo de comunicaÃ§Ã£o
   - O que NUNCA fazer
   - Exemplos de bom/ruim

2. **Contexto do Paciente** (linhas 158-176)
   - InformaÃ§Ãµes do paciente
   - Status do cadastro
   - HistÃ³rico
   - Agendamentos
   - PreferÃªncias

3. **Conversa Atual** (linhas 167-175)
   - Todas as mensagens trocadas
   - Aviso para nÃ£o repetir perguntas

4. **Conhecimento da ClÃ­nica** (linhas 178-179)
   - Procedimentos
   - ConvÃªnios
   - PreÃ§os
   - Pacotes

5. **Regras de TransferÃªncia** (linhas 181-182)
   - Quando transferir
   - Para qual fila

6. **Formato de Resposta** (linhas 184-212)
   - Estrutura JSON obrigatÃ³ria
   - Actions permitidas
   - Entities esperadas

7. **DetecÃ§Ã£o de IntenÃ§Ã£o** (linhas 214-225)
   - Como identificar intenÃ§Ãµes
   - Palavras-chave

8. **Exemplos Perfeitos** (linhas 227-278)
   - 5 exemplos de conversas ideais
   - Como imitar o estilo

9. **Regras CrÃ­ticas de Contexto** (linhas 282-301)
   - Nunca repetir perguntas
   - Usar informaÃ§Ãµes jÃ¡ coletadas
   - Manter fluxo linear

10. **Regra de Agendamento** (linhas 304-385)
    - Cadastro SEMPRE vem primeiro
    - Fluxo obrigatÃ³rio
    - Entities obrigatÃ³rias

11. **Regras de Valores** (linhas 386-392)
    - Sempre perguntar unidade antes
    - Valores variam por unidade

12. **Regras de ConvÃªnios** (linhas 393-413)
    - ConvÃªnios normais vs com desconto
    - Nunca inventar valores

13. **Proatividade** (linhas 415-448)
    - Quando oferecer sugestÃµes
    - Como ser sutil

14. **Auto-CorreÃ§Ã£o** (linhas 450-472)
    - Como corrigir erros
    - Exemplos

15. **InstruÃ§Ãµes Finais** (linhas 474-489)
    - FormataÃ§Ã£o
    - Tom
    - PersonalizaÃ§Ã£o

---

## ğŸ—„ï¸ ConfiguraÃ§Ã£o no Banco de Dados

### Tabela: `AIConfiguration`

**Campos importantes**:
- `systemPrompt`: Prompt base (pode ser editado)
- `personality`: Personalidade
- `tone`: Tom de voz
- `useEmojis`: Usar emojis?
- `offerPackages`: Oferecer pacotes?
- `askInsurance`: Perguntar convÃªnio?
- `temperature`: Temperatura do GPT (0.7)
- `maxTokens`: Tokens mÃ¡ximos (1000)
- `isActive`: EstÃ¡ ativa?

### Tabela: `AIExample`

**Few-Shot Learning**: Exemplos de conversas perfeitas
- `userMessage`: Mensagem do usuÃ¡rio
- `botResponse`: Resposta esperada
- `expectedIntent`: IntenÃ§Ã£o esperada
- `expectedAction`: AÃ§Ã£o esperada
- `entities`: Entidades extraÃ­das
- `category`: Categoria (AGENDAR, INFORMACAO, etc)
- `priority`: Prioridade (ordem de importÃ¢ncia)

### Tabela: `TransferRule`

**Regras de TransferÃªncia**: Quando transferir para humano
- `keywords`: Palavras-chave que ativam
- `intents`: IntenÃ§Ãµes que ativam
- `targetQueue`: Fila de destino
- `transferMessage`: Mensagem de transferÃªncia
- `priority`: Prioridade da regra

---

## ğŸš€ Como Subir para o Railway

### Passo 1: Garantir que o Seed foi Executado

O seed cria a configuraÃ§Ã£o inicial no banco. Execute no Railway:

```bash
npx tsx scripts/seed_ai_configuration.ts
```

**OU** adicione ao script de deploy:

```json
{
  "scripts": {
    "deploy:prod": "npx prisma db push && npx tsx scripts/seed_ai_configuration.ts && npx tsx scripts/import_workflow_definitivo.ts && npx tsx api/server.ts"
  }
}
```

### Passo 2: Verificar ConfiguraÃ§Ã£o no Banco

No Railway Shell, execute:

```bash
npx tsx -e "
import prisma from './api/prisma/client.js';
(async () => {
  const config = await prisma.aIConfiguration.findFirst({ where: { isActive: true } });
  console.log('Config ativa:', config ? 'SIM âœ…' : 'NÃƒO âŒ');
  if (config) {
    console.log('ID:', config.id);
    console.log('Nome:', config.name);
    console.log('Exemplos:', await prisma.aIExample.count({ where: { configId: config.id } }));
    console.log('Regras:', await prisma.transferRule.count({ where: { configId: config.id } }));
  }
  await prisma.\$disconnect();
})()
"
```

### Passo 3: VariÃ¡veis de Ambiente no Railway

Garantir que estas variÃ¡veis estÃ£o configuradas:

```
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o
OPENAI_TIMEOUT=20000
```

### Passo 4: Testar a IA

Envie uma mensagem de teste e verifique os logs:

```bash
# No Railway, verifique os logs:
# Deve aparecer:
# - "ğŸ¤– Gerando resposta conversacional"
# - "ğŸ” CONTEXTO COMPLETO"
# - "âœ… Resposta gerada"
```

---

## ğŸ”§ Como Melhorar a Fluidez

### 1. Ajustar o Prompt Base

**Arquivo**: `api/services/aiConfigurationService.ts`  
**MÃ©todo**: `buildDynamicPrompt()`

**O que ajustar**:
- Personalidade (linhas 104-157)
- Exemplos perfeitos (linhas 227-278)
- Regras crÃ­ticas (linhas 282-385)

### 2. Adicionar Exemplos no Banco

```typescript
// Via script ou interface
await prisma.aIExample.create({
  data: {
    configId: configId,
    name: 'Exemplo de Conversa Fluida',
    category: 'AGENDAR',
    userMessage: 'quero agendar fisioterapia',
    expectedIntent: 'AGENDAR',
    expectedAction: 'collect_data',
    botResponse: 'Perfeito! Vou te ajudar...',
    entities: { procedimento: 'Fisioterapia' },
    confidence: 0.95,
    priority: 1
  }
})
```

### 3. Ajustar Regras de TransferÃªncia

```typescript
await prisma.transferRule.create({
  data: {
    configId: configId,
    name: 'Nova Regra',
    keywords: ['palavra1', 'palavra2'],
    intents: ['AGENDAR'],
    targetQueue: 'AGUARDANDO',
    priority: 5
  }
})
```

### 4. Editar ConfiguraÃ§Ã£o Ativa

```typescript
await prisma.aIConfiguration.update({
  where: { id: configId },
  data: {
    systemPrompt: 'Novo prompt...',
    temperature: 0.8, // Mais criativo
    maxTokens: 1500   // Respostas mais longas
  }
})
```

---

## ğŸ“Š Monitoramento

### Logs Importantes

1. **GeraÃ§Ã£o de Resposta**:
   ```
   ğŸ¤– Gerando resposta conversacional para: "..."
   ğŸ” CONTEXTO COMPLETO: {...}
   âœ… Resposta gerada: {...}
   ```

2. **Contexto**:
   ```
   âœ… Contexto construÃ­do para {phone}:
      â€¢ Paciente: {name}
      â€¢ Conversas anteriores: {count}
      â€¢ Agendamentos: {count}
   ```

3. **Prompt**:
   ```
   ğŸ“œ HistÃ³rico de {count} mensagens incluÃ­do
   ğŸ“ MENSAGEM ATUAL DO USUÃRIO: "..."
   ```

### MÃ©tricas para Acompanhar

- **ConfianÃ§a mÃ©dia**: `confidence` nas respostas
- **Taxa de transferÃªncia**: Quantas vezes transfere vs continua
- **IntenÃ§Ãµes detectadas**: DistribuiÃ§Ã£o de intents
- **Tempo de resposta**: LatÃªncia do GPT

---

## âš ï¸ Pontos de AtenÃ§Ã£o

### 1. Custo da API OpenAI

- **Modelo**: gpt-4o (mais caro, mas melhor)
- **Tokens**: ~1000 por mensagem
- **Custo estimado**: ~$0.01-0.03 por conversa completa
- **Monitorar**: Usar dashboard da OpenAI

### 2. LatÃªncia

- **Timeout**: 20 segundos (configurÃ¡vel)
- **Tempo mÃ©dio**: 2-5 segundos
- **OtimizaÃ§Ãµes**: Cache de contexto, paralelizaÃ§Ã£o

### 3. Contexto Limitado

- **HistÃ³rico**: Ãšltimas 20 mensagens
- **Tokens mÃ¡ximos**: 1000 na resposta
- **SoluÃ§Ã£o**: Resumir histÃ³rico antigo

### 4. Prompt Muito Longo

- **Tamanho atual**: ~15.000 caracteres
- **Limite GPT-4o**: 128k tokens
- **Risco**: Custo alto, latÃªncia maior

---

## ğŸ¯ Checklist para Deploy no Railway

- [ ] Seed executado (`seed_ai_configuration.ts`)
- [ ] ConfiguraÃ§Ã£o ativa no banco
- [ ] Exemplos criados (pelo menos 5)
- [ ] Regras de transferÃªncia criadas
- [ ] VariÃ¡veis de ambiente configuradas
- [ ] `OPENAI_API_KEY` vÃ¡lida
- [ ] Teste de mensagem funcionando
- [ ] Logs mostrando contexto sendo construÃ­do
- [ ] Respostas sendo geradas corretamente
- [ ] TransferÃªncias funcionando

---

## ğŸ“ Resumo

**A fluidez vem de**:
1. âœ… Prompt bem estruturado (hardcoded em `aiConfigurationService.ts`)
2. âœ… Contexto rico (histÃ³rico, paciente, agendamentos)
3. âœ… Exemplos de conversas (few-shot learning)
4. âœ… Regras claras de negÃ³cio
5. âœ… GPT-4o (modelo mais inteligente)

**Para subir no Railway**:
1. Execute o seed
2. Verifique configuraÃ§Ã£o ativa
3. Configure variÃ¡veis de ambiente
4. Teste e monitore

**Para melhorar**:
1. Ajuste o prompt base
2. Adicione mais exemplos
3. Refine regras de transferÃªncia
4. Monitore mÃ©tricas
