import OpenAI from 'openai';
import { WorkflowNode, WorkflowExecutionContext, ConnectionMap, NodeExecutionResult } from '../core/types';

/**
 * Executes a GPT_RESPONSE node
 * GPT_RESPONSE nodes use GPT to classify user intent or generate responses
 */
export async function executeGPTNode(
  node: WorkflowNode,
  context: WorkflowExecutionContext,
  connections: ConnectionMap
): Promise<NodeExecutionResult> {
  const apiKey = process.env.OPENAI_API_KEY;
  
  console.log(`ü§ñ [GPT] Starting GPT node execution: ${node.id}`);
  
  if (!apiKey) {
    console.error('ü§ñ [GPT] OPENAI_API_KEY not configured');
    context.workflowLogs.push('‚ùå OPENAI_API_KEY n√£o configurada');
    return { 
      nextNodeId: undefined, 
      response: 'Desculpe, servi√ßo temporariamente indispon√≠vel.', 
      shouldStop: true 
    };
  }
  
  // Get user message
  const userMessage = (context.message || '').trim();
  
  // Check for generic/empty messages
  const genericMessages = ['oi', 'ol√°', 'ola', 'hey', 'hi', 'hello', 'ok', 'okay', 'beleza'];
  const isGenericMessage = genericMessages.some(g => 
    userMessage.toLowerCase() === g || 
    userMessage.toLowerCase().length <= 10 && userMessage.toLowerCase().includes(g)
  );
  
  if (!userMessage || isGenericMessage) {
    console.log(`ü§ñ [GPT] Skipping GPT for generic/empty message: "${userMessage}"`);
    return { 
      nextNodeId: undefined, 
      response: '', 
      shouldStop: true 
    };
  }
  
  // Check for clinic selection response (shouldn't be processed by GPT)
  const isClinicSelection = ['1', '2', 'um', 'dois'].includes(userMessage.toLowerCase()) ||
                           ['vieiralves', 'vieira', 'sao jose', 's√£o jos√©'].some(k => 
                             userMessage.toLowerCase().includes(k)
                           );
  
  if (isClinicSelection && !context.userData.selectedClinic) {
    console.log(`ü§ñ [GPT] Skipping GPT for clinic selection: "${userMessage}"`);
    return { 
      nextNodeId: undefined, 
      response: '', 
      shouldStop: true 
    };
  }
  
  try {
    const client = new OpenAI({ apiKey });
    const clinicCode = context.userData.selectedClinic || context.userData.clinicCode || 'vieiralves';
    
    // Import clinic data for context
    const { formatClinicDataForGPT } = await import('../utils/clinicDataFormatter');
    const clinicContext = formatClinicDataForGPT(clinicCode);
    
    const systemPrompt = node.content.systemPrompt || 
      `Voc√™ √© um classificador de inten√ß√£o para cl√≠nica de fisioterapia. Analise a mensagem do usu√°rio e classifique em UMA das op√ß√µes:

1) VALORES - perguntas sobre pre√ßos, valores particulares, pacotes
2) CONV√äNIOS - perguntas sobre conv√™nios aceitos, planos de sa√∫de, cobertura
3) LOCALIZA√á√ÉO - perguntas sobre endere√ßo, como chegar, hor√°rios, contato
4) PROCEDIMENTO - perguntas sobre o que √© um procedimento, benef√≠cios, dura√ß√£o, indica√ß√µes
5) AGENDAR - desejo de marcar consulta, agendar, marcar hor√°rio (ex: "quero agendar", "quero gendar", "marcar consulta")
6) ATENDENTE - pedido para falar com humano, atendente, pessoa

IMPORTANTE: "quero agendar", "quero gendar" (com erro de digita√ß√£o), "marcar", "agendar consulta" = SEMPRE porta 5 (AGENDAR).

CONTEXTO DA CL√çNICA (para refer√™ncia):
${clinicContext}

Responda APENAS com JSON no formato {"intent_port":"<1|2|3|4|5|6>","brief":"<mensagem curta>","confidence":<0..1>}.`;
    
    // Build conversation history
    const historyContext = context.conversationHistory
      .slice(-4)
      .map(h => `${h.role === 'user' ? 'Usu√°rio' : 'Bot'}: ${h.content}`)
      .join('\n');
    
    const contextInfo = context.userData.lastTopic ? 
      `\n\nContexto: O usu√°rio estava perguntando sobre ${context.userData.lastTopic}.` : '';
    
    const prompt = `${systemPrompt}\n\nHist√≥rico recente:\n${historyContext}${contextInfo}\n\nMensagem atual: "${userMessage}"`;
    
    // Log GPT call details
    context.workflowLogs.push(`ü§ñ [GPT] ==========================================`);
    context.workflowLogs.push(`ü§ñ [GPT] üì® MENSAGEM DO USU√ÅRIO: "${userMessage}"`);
    context.workflowLogs.push(`ü§ñ [GPT] üìã HIST√ìRICO (√∫ltimas 4 mensagens):`);
    context.workflowLogs.push(historyContext || '(sem hist√≥rico)');
    context.workflowLogs.push(`ü§ñ [GPT] üè• CL√çNICA SELECIONADA: ${context.userData.selectedClinic || 'nenhuma'}`);
    context.workflowLogs.push(`ü§ñ [GPT] üìù √öLTIMO T√ìPICO: ${context.userData.lastTopic || 'nenhum'}`);
    context.workflowLogs.push(`ü§ñ [GPT] ‚è≥ Chamando GPT-4o...`);
    
    console.log(`ü§ñ [GPT] Calling GPT with message: "${userMessage}"`);
    
    const completion = await client.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: 'Responda apenas com JSON v√°lido sem texto extra.' },
        { role: 'user', content: prompt }
      ],
      temperature: 0,
      max_tokens: 100
    }, { timeout: 30000 });
    
    let content = completion.choices?.[0]?.message?.content || '';
    
    context.workflowLogs.push(`ü§ñ [GPT] üì• RESPOSTA RAW DO GPT:`);
    context.workflowLogs.push(content);
    
    // Clean up markdown code blocks
    content = content.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
    
    let parsed: any = {};
    try {
      parsed = JSON.parse(content);
      context.workflowLogs.push(`ü§ñ [GPT] ‚úÖ JSON PARSEADO COM SUCESSO:`);
      context.workflowLogs.push(JSON.stringify(parsed, null, 2));
    } catch (e) {
      context.workflowLogs.push(`ü§ñ [GPT] ‚ùå ERRO AO PARSEAR JSON: ${e}`);
      
      // Try to extract intent_port from text
      const match = content.match(/"intent_port"\s*:\s*"([1-6])"/);
      if (match) {
        parsed = {
          intent_port: match[1],
          confidence: 0.7,
          brief: 'Inten√ß√£o detectada'
        };
        context.workflowLogs.push(`ü§ñ [GPT] Extra√≠do intent_port: ${match[1]}`);
      } else {
        context.workflowLogs.push(`ü§ñ [GPT] N√£o foi poss√≠vel extrair intent_port`);
        return {
          nextNodeId: undefined,
          response: 'N√£o entendi. Voc√™ quer saber sobre valores, conv√™nios, localiza√ß√£o ou agendar?',
          shouldStop: true
        };
      }
    }
    
    const port = String(parsed.intent_port || '').trim();
    const confidence = Number(parsed.confidence ?? 0.5);
    const brief = String(parsed.brief || '').trim();
    const threshold = Number(process.env.GPT_CONFIDENCE_THRESHOLD || 0.5);
    
    context.workflowLogs.push(`ü§ñ [GPT] üìä RESULTADO DA CLASSIFICA√á√ÉO:`);
    context.workflowLogs.push(`ü§ñ [GPT]    Porta selecionada: ${port || 'NENHUMA'}`);
    context.workflowLogs.push(`ü§ñ [GPT]    Confian√ßa: ${confidence} (threshold: ${threshold})`);
    context.workflowLogs.push(`ü§ñ [GPT]    Brief: "${brief}"`);
    
    if (!['1', '2', '3', '4', '5', '6'].includes(port)) {
      context.workflowLogs.push(`ü§ñ [GPT] ‚ùå PORTA INV√ÅLIDA: "${port}"`);
      return {
        nextNodeId: undefined,
        response: 'N√£o entendi. Voc√™ quer saber sobre valores, conv√™nios, localiza√ß√£o ou agendar?',
        shouldStop: true
      };
    }
    
    if (confidence < threshold) {
      context.workflowLogs.push(`ü§ñ [GPT] ‚ö†Ô∏è CONFIAN√áA BAIXA (${confidence} < ${threshold}). Solicitando confirma√ß√£o.`);
      return {
        nextNodeId: undefined,
        response: 'üîé S√≥ para confirmar: deseja saber sobre valores (1), conv√™nios (2), localiza√ß√£o (3), procedimentos (4) ou agendar (5)?',
        shouldStop: true
      };
    }
    
    // Find connection by port
    const nodeConnections = connections.get(node.id) || [];
    const targetConnection = nodeConnections.find(c => c.port === port);
    const nextNodeId = targetConnection?.targetId;
    
    context.workflowLogs.push(`ü§ñ [GPT] ‚úÖ CLASSIFICA√á√ÉO ACEITA!`);
    context.workflowLogs.push(`ü§ñ [GPT]    Conex√£o: porta ${port} ‚Üí node "${nextNodeId || 'NENHUM'}"`);
    context.workflowLogs.push(`ü§ñ [GPT] ==========================================`);
    
    // Update context based on intent
    if (port === '1') {
      context.userData.lastTopic = 'price';
      // Save user message to help API_CALL detect specific procedure
      context.userData.lastPriceQuery = userMessage;
    }
    else if (port === '2') context.userData.lastTopic = 'insurance';
    else if (port === '3') context.userData.lastTopic = 'location';
    else if (port === '4') context.userData.lastTopic = 'procedure_info';
    else if (port === '5') {
      context.userData.lastTopic = 'scheduling';
      context.userData.isSchedulingIntent = true;
    }
    else if (port === '6') context.userData.lastTopic = 'human';
    
    console.log(`ü§ñ [GPT] Intent classified - Port: ${port}, Next node: ${nextNodeId}`);
    
    return {
      nextNodeId,
      response: brief || '',
      shouldStop: false,
      autoAdvance: true
    };
    
  } catch (error: any) {
    console.error(`ü§ñ [GPT] Error calling GPT:`, error);
    context.workflowLogs.push(`ü§ñ [GPT] ‚ùå ERRO: ${error.message}`);
    
    return {
      nextNodeId: undefined,
      response: 'Desculpe, tive um problema ao processar sua mensagem. Pode repetir?',
      shouldStop: true
    };
  }
}

