import OpenAI from 'openai';
import { WorkflowNode, WorkflowExecutionContext, ConnectionMap, NodeExecutionResult } from '../core/types';

/**
 * Executes a GPT_RESPONSE node
 * GPT_RESPONSE nodes use GPT to classify user intent or generate responses
 */
export async function executeGPTNode(
  node: WorkflowNode,
  context: WorkflowExecutionContext,
  connections: ConnectionMap
): Promise<NodeExecutionResult> {
  const apiKey = process.env.OPENAI_API_KEY;
  
  console.log(`ü§ñ [GPT] Starting GPT node execution: ${node.id}`);
  
  if (!apiKey) {
    console.error('ü§ñ [GPT] OPENAI_API_KEY not configured');
    context.workflowLogs.push('‚ùå OPENAI_API_KEY n√£o configurada');
    return { 
      nextNodeId: undefined, 
      response: 'Desculpe, servi√ßo temporariamente indispon√≠vel.', 
      shouldStop: true 
    };
  }
  
  // Get user message
  const userMessage = (context.message || '').trim();
  
  // Check for generic/empty messages
  const genericMessages = ['oi', 'ol√°', 'ola', 'hey', 'hi', 'hello', 'ok', 'okay', 'beleza'];
  const isGenericMessage = genericMessages.some(g => 
    userMessage.toLowerCase() === g || 
    userMessage.toLowerCase().length <= 10 && userMessage.toLowerCase().includes(g)
  );
  
  if (!userMessage || isGenericMessage) {
    console.log(`ü§ñ [GPT] Skipping GPT for generic/empty message: "${userMessage}"`);
    return { 
      nextNodeId: undefined, 
      response: '', 
      shouldStop: true 
    };
  }
  
  // Check for clinic selection response (shouldn't be processed by GPT)
  const isClinicSelection = ['1', '2', 'um', 'dois'].includes(userMessage.toLowerCase()) ||
                           ['vieiralves', 'vieira', 'sao jose', 's√£o jos√©'].some(k => 
                             userMessage.toLowerCase().includes(k)
                           );
  
  if (isClinicSelection && !context.userData.selectedClinic) {
    console.log(`ü§ñ [GPT] Skipping GPT for clinic selection: "${userMessage}"`);
    return { 
      nextNodeId: undefined, 
      response: '', 
      shouldStop: true 
    };
  }
  
  try {
    const client = new OpenAI({ apiKey });
    const clinicCode = context.userData.selectedClinic || context.userData.clinicCode || 'vieiralves';
    
    // Import clinic data for context
    const { formatClinicDataForGPT } = await import('../utils/clinicDataFormatter');
    const clinicContext = formatClinicDataForGPT(clinicCode);
    
    const systemPrompt = node.content.systemPrompt || 
      `Voc√™ √© um assistente virtual amig√°vel e prestativo de uma cl√≠nica de fisioterapia. 

SEU OBJETIVO:
1. RESPONDER de forma CONVERSACIONAL, √öTIL e AMIG√ÅVEL
2. CLASSIFICAR a inten√ß√£o do usu√°rio para roteamento interno

CONTEXTO DA CL√çNICA:
${clinicContext}

CATEGORIAS DE INTEN√á√ÉO (para roteamento):
1) VALORES - perguntas sobre pre√ßos, valores particulares, pacotes
2) CONV√äNIOS - perguntas sobre conv√™nios aceitos, planos de sa√∫de, cobertura
3) LOCALIZA√á√ÉO - perguntas sobre endere√ßo, como chegar, hor√°rios, contato
4) PROCEDIMENTO - perguntas sobre o que √© um procedimento, benef√≠cios, dura√ß√£o, indica√ß√µes
5) AGENDAR - desejo de marcar consulta, agendar, marcar hor√°rio, men√ß√µes a encaminhamento m√©dico
6) ATENDENTE - pedido para falar com humano, atendente, pessoa

REGRAS IMPORTANTES PARA O CAMPO "brief":
‚ùå NUNCA responda apenas: "Encaminhamento para fisioterapia", "Refer√™ncia a procedimento", "Pergunta sobre valores"
‚úÖ SEMPRE fa√ßa uma pergunta ou d√™ uma resposta √öTIL e CONVERSACIONAL
‚úÖ Use emojis para deixar mais amig√°vel
‚úÖ Fa√ßa perguntas esclarecedoras quando necess√°rio
‚úÖ Reconhe√ßa o que o usu√°rio disse ANTES de perguntar mais

CASOS ESPECIAIS:
- "encaminhamento" ou "sess√µes" ‚Üí USE OS PROCEDIMENTOS DA CL√çNICA para dar op√ß√µes reais, pergunte qual, porta 5
- "sim", "isso", "correto" ‚Üí Reconhe√ßa positivamente, pergunte como pode ajudar, porta 5
- "posso parcelar?" ‚Üí Mencione que vai ajudar com pagamento, porta 1
- Mensagens vagas ‚Üí Seja prestativo, USE OS DADOS DA CL√çNICA para oferecer op√ß√µes reais

IMPORTANTE: Quando o usu√°rio mencionar "encaminhamento" ou "sess√µes", SEMPRE inclua a lista real de procedimentos dispon√≠veis no brief.

FORMATO DE RESPOSTA (JSON):
{"intent_port":"<1-6>","brief":"<RESPOSTA CONVERSACIONAL COMPLETA usando dados reais da cl√≠nica (m√≠nimo 80 caracteres)>","confidence":<0-1>}

EXEMPLOS CORRETOS:
‚ùå MAU: {"intent_port":"5","brief":"Encaminhamento para fisioterapia","confidence":0.9}
‚úÖ BOM: {"intent_port":"5","brief":"√ìtimo! Voc√™ tem encaminhamento para fisioterapia! üè•\\n\\nTemos estes procedimentos dispon√≠veis:\\n- Fisioterapia Ortop√©dica (R$ 90,00)\\n- Fisioterapia Neurol√≥gica (R$ 100,00)\\n- RPG (R$ 120,00)\\n- Acupuntura (R$ 180,00)\\n\\nPara qual procedimento espec√≠fico voc√™ foi encaminhado?","confidence":0.9}

‚ùå MAU: {"intent_port":"5","brief":"Refer√™ncia a procedimento anterior","confidence":0.7}
‚úÖ BOM: {"intent_port":"5","brief":"Perfeito! Entendi que voc√™ quer agendar. üìÖ\\n\\nTemos diversos procedimentos: Fisioterapia Ortop√©dica, Neurol√≥gica, RPG, Acupuntura, Fisioterapia P√©lvica.\\n\\nQual desses voc√™ precisa?","confidence":0.8}

‚ùå MAU: {"intent_port":"1","brief":"Pergunta sobre parcelamento","confidence":0.8}
‚úÖ BOM: {"intent_port":"1","brief":"Sobre formas de pagamento e parcelamento, posso te ajudar! üí≥\\n\\nTemos procedimentos desde R$ 90,00 at√© R$ 220,00, com pacotes dispon√≠veis.\\n\\nQual procedimento voc√™ gostaria de fazer?","confidence":0.9}`;
    
    // Build conversation history
    const historyContext = context.conversationHistory
      .slice(-4)
      .map(h => `${h.role === 'user' ? 'Usu√°rio' : 'Bot'}: ${h.content}`)
      .join('\n');
    
    const contextInfo = context.userData.lastTopic ? 
      `\n\nContexto: O usu√°rio estava perguntando sobre ${context.userData.lastTopic}.` : '';
    
    const prompt = `${systemPrompt}\n\nHist√≥rico recente:\n${historyContext}${contextInfo}\n\nMensagem atual: "${userMessage}"`;
    
    // Log GPT call details
    context.workflowLogs.push(`ü§ñ [GPT] ==========================================`);
    context.workflowLogs.push(`ü§ñ [GPT] üì® MENSAGEM DO USU√ÅRIO: "${userMessage}"`);
    context.workflowLogs.push(`ü§ñ [GPT] üìã HIST√ìRICO (√∫ltimas 4 mensagens):`);
    context.workflowLogs.push(historyContext || '(sem hist√≥rico)');
    context.workflowLogs.push(`ü§ñ [GPT] üè• CL√çNICA SELECIONADA: ${context.userData.selectedClinic || 'nenhuma'}`);
    context.workflowLogs.push(`ü§ñ [GPT] üìù √öLTIMO T√ìPICO: ${context.userData.lastTopic || 'nenhum'}`);
    context.workflowLogs.push(`ü§ñ [GPT] ‚è≥ Chamando GPT-4o...`);
    
    console.log(`ü§ñ [GPT] Calling GPT with message: "${userMessage}"`);
    
    // Use faster/cheaper model for classification (gpt-4o-mini by default)
    const classificationModel = process.env.OPENAI_CLASSIFICATION_MODEL || 'gpt-4o-mini';
    
    console.log(`ü§ñ [GPT] Using model: ${classificationModel} for intent classification`);
    
    const completion = await client.chat.completions.create({
      model: classificationModel,
      messages: [
        { role: 'system', content: 'Responda apenas com JSON v√°lido sem texto extra.' },
        { role: 'user', content: prompt }
      ],
      temperature: 0.3, // Slightly higher for more natural brief
      max_tokens: 150 // More tokens for better brief responses
    }, { timeout: 30000 });
    
    let content = completion.choices?.[0]?.message?.content || '';
    
    context.workflowLogs.push(`ü§ñ [GPT] üì• RESPOSTA RAW DO GPT:`);
    context.workflowLogs.push(content);
    
    // Clean up markdown code blocks
    content = content.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
    
    let parsed: any = {};
    try {
      parsed = JSON.parse(content);
      context.workflowLogs.push(`ü§ñ [GPT] ‚úÖ JSON PARSEADO COM SUCESSO:`);
      context.workflowLogs.push(JSON.stringify(parsed, null, 2));
    } catch (e) {
      context.workflowLogs.push(`ü§ñ [GPT] ‚ùå ERRO AO PARSEAR JSON: ${e}`);
      
      // Try to extract intent_port from text
      const match = content.match(/"intent_port"\s*:\s*"([1-6])"/);
      if (match) {
        parsed = {
          intent_port: match[1],
          confidence: 0.7,
          brief: 'Inten√ß√£o detectada'
        };
        context.workflowLogs.push(`ü§ñ [GPT] Extra√≠do intent_port: ${match[1]}`);
      } else {
        context.workflowLogs.push(`ü§ñ [GPT] N√£o foi poss√≠vel extrair intent_port`);
        return {
          nextNodeId: undefined,
          response: 'N√£o entendi. Voc√™ quer saber sobre valores, conv√™nios, localiza√ß√£o ou agendar?',
          shouldStop: true
        };
      }
    }
    
    const port = String(parsed.intent_port || '').trim();
    const confidence = Number(parsed.confidence ?? 0.5);
    const brief = String(parsed.brief || '').trim();
    const threshold = Number(process.env.GPT_CONFIDENCE_THRESHOLD || 0.5);
    
    context.workflowLogs.push(`ü§ñ [GPT] üìä RESULTADO DA CLASSIFICA√á√ÉO:`);
    context.workflowLogs.push(`ü§ñ [GPT]    Porta selecionada: ${port || 'NENHUMA'}`);
    context.workflowLogs.push(`ü§ñ [GPT]    Confian√ßa: ${confidence} (threshold: ${threshold})`);
    context.workflowLogs.push(`ü§ñ [GPT]    Brief: "${brief}"`);
    
    if (!['1', '2', '3', '4', '5', '6'].includes(port)) {
      context.workflowLogs.push(`ü§ñ [GPT] ‚ùå PORTA INV√ÅLIDA: "${port}"`);
      return {
        nextNodeId: undefined,
        response: 'N√£o entendi. Voc√™ quer saber sobre valores, conv√™nios, localiza√ß√£o ou agendar?',
        shouldStop: true
      };
    }
    
    if (confidence < threshold) {
      context.workflowLogs.push(`ü§ñ [GPT] ‚ö†Ô∏è CONFIAN√áA BAIXA (${confidence} < ${threshold}). Solicitando confirma√ß√£o.`);
      return {
        nextNodeId: undefined,
        response: 'üîé S√≥ para confirmar: deseja saber sobre valores (1), conv√™nios (2), localiza√ß√£o (3), procedimentos (4) ou agendar (5)?',
        shouldStop: true
      };
    }
    
    // Find connection by port
    const nodeConnections = connections.get(node.id) || [];
    const targetConnection = nodeConnections.find(c => c.port === port);
    const nextNodeId = targetConnection?.targetId;
    
    context.workflowLogs.push(`ü§ñ [GPT] ‚úÖ CLASSIFICA√á√ÉO ACEITA!`);
    context.workflowLogs.push(`ü§ñ [GPT]    Conex√£o: porta ${port} ‚Üí node "${nextNodeId || 'NENHUM'}"`);
    context.workflowLogs.push(`ü§ñ [GPT] ==========================================`);
    
    // Update context based on intent
    if (port === '1') {
      context.userData.lastTopic = 'price';
      // Save user message to help API_CALL detect specific procedure
      context.userData.lastPriceQuery = userMessage;
    }
    else if (port === '2') context.userData.lastTopic = 'insurance';
    else if (port === '3') context.userData.lastTopic = 'location';
    else if (port === '4') context.userData.lastTopic = 'procedure_info';
    else if (port === '5') {
      context.userData.lastTopic = 'scheduling';
      context.userData.isSchedulingIntent = true;
    }
    else if (port === '6') context.userData.lastTopic = 'human';
    
    console.log(`ü§ñ [GPT] Intent classified - Port: ${port}, Next node: ${nextNodeId}`);
    
    // Ensure response is conversational (not just a classification)
    let conversationalResponse = brief || '';
    
    // If brief is too short or looks like a classification, make it more conversational WITH REAL DATA
    if (conversationalResponse.length < 50 || 
        conversationalResponse.match(/^(encaminhamento|refer[e√™]ncia|pergunta|sobre)/i)) {
      
      console.log(`ü§ñ [GPT] ‚ö†Ô∏è Brief muito curto ou n√£o conversacional: "${conversationalResponse}"`);
      
      // Get procedures list for better responses
      const clinicCode = context.userData.selectedClinic || 'vieiralves';
      const clinicInfo = clinicDataService.getClinicInfo(clinicCode);
      const mainProcedures = (clinicInfo.procedures || []).slice(0, 5).map((p: any) => {
        const price = p.prices?.[clinicCode];
        const priceText = typeof price === 'number' ? `R$ ${price},00` : 'consultar';
        return `- ${p.name} (${priceText})`;
      }).join('\n');
      
      // Generate better response based on intent WITH REAL DATA
      const conversationalMap: Record<string, string> = {
        '1': `Entendi que voc√™ quer saber sobre valores! üí∞\n\nNossos principais procedimentos:\n${mainProcedures}\n\nQual procedimento te interessa?`,
        '2': `Legal! Voc√™ quer saber sobre conv√™nios. üè•\n\nAceitamos: ${(clinicInfo.acceptedInsurance || []).slice(0, 5).join(', ')} e outros.\n\nQual conv√™nio voc√™ tem?`,
        '3': `Vou te passar nossa localiza√ß√£o! üìç\n\n${clinicLocations[clinicCode].name}\n${clinicLocations[clinicCode].address}\n${clinicLocations[clinicCode].phone}\n\nPrecisa saber como chegar?`,
        '4': `Voc√™ quer saber sobre procedimentos! üìù\n\nOferecemos:\n${mainProcedures}\n\nQual procedimento te interessa?`,
        '5': `√ìtimo! Vamos agendar sua consulta! üìÖ\n\nTemos dispon√≠veis:\n${mainProcedures}\n\nPara qual procedimento voc√™ precisa agendar?`,
        '6': `Entendi! Vou te conectar com um atendente humano. ‚è≥ Aguarde um momento...`
      };
      
      conversationalResponse = conversationalMap[port] || conversationalResponse;
      context.workflowLogs.push(`ü§ñ [GPT] ‚ú® Resposta melhorada com dados reais: "${conversationalResponse.substring(0, 100)}..."`);
    }
    
    return {
      nextNodeId,
      response: conversationalResponse,
      shouldStop: false,
      autoAdvance: true
    };
    
  } catch (error: any) {
    console.error(`ü§ñ [GPT] Error calling GPT:`, error);
    context.workflowLogs.push(`ü§ñ [GPT] ‚ùå ERRO: ${error.message}`);
    
    return {
      nextNodeId: undefined,
      response: 'Desculpe, tive um problema ao processar sua mensagem. Pode repetir?',
      shouldStop: true
    };
  }
}

