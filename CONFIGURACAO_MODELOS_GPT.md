# ü§ñ Configura√ß√£o de Modelos GPT (Dual-Model System)

## üéØ Sistema Implementado

O sistema agora usa **dois modelos diferentes** conforme a necessidade:

### 1. **Classifica√ß√£o de Inten√ß√£o** (R√°pido e Barato)
- **Modelo**: `gpt-4o-mini` (padr√£o)
- **Uso**: Classificar a inten√ß√£o do usu√°rio (valores, conv√™nios, agendar, etc.)
- **Por que**: √â r√°pido, barato e excelente para tarefas simples de classifica√ß√£o
- **Arquivo**: `src/services/workflow/executors/gptExecutor.ts`

### 2. **Respostas Complexas** (Poderoso e Contextualizado)
- **Modelo**: `gpt-4o` ou `gpt-4-turbo` (configur√°vel)
- **Uso**: Gerar respostas ricas e contextualizadas
- **Por que**: Melhor para gerar respostas longas e bem estruturadas
- **Arquivo**: `src/services/workflow/executors/gptResponseExecutor.ts`

## üìä Compara√ß√£o de Modelos

| Modelo | Velocidade | Custo | Melhor Para | Tokens |
|--------|------------|-------|-------------|--------|
| **gpt-4o-mini** | ‚ö°‚ö°‚ö° Muito r√°pido | üí∞ Muito barato | Classifica√ß√£o, tarefas simples | 128k |
| **gpt-4o** | ‚ö°‚ö° R√°pido | üí∞üí∞ Barato | Respostas ricas, contextualizadas | 128k |
| **gpt-4-turbo** | ‚ö° M√©dio | üí∞üí∞üí∞ Mais caro | Respostas muito complexas | 128k |
| **o1-preview** | üêå Lento | üí∞üí∞üí∞üí∞ Muito caro | Racioc√≠nio complexo | 128k |

### Custos (aproximados por 1M tokens):

| Modelo | Input | Output |
|--------|-------|--------|
| gpt-4o-mini | $0.15 | $0.60 |
| gpt-4o | $2.50 | $10.00 |
| gpt-4-turbo | $10.00 | $30.00 |
| o1-preview | $15.00 | $60.00 |

**Exemplo de economia:**
- 1000 classifica√ß√µes com gpt-4o-mini: ~$0.20
- 1000 classifica√ß√µes com gpt-4o: ~$2.50
- **Economia: 90%+**

## ‚öôÔ∏è Configura√ß√£o (.env)

```bash
# Modelo para classifica√ß√£o (r√°pido e barato)
OPENAI_CLASSIFICATION_MODEL="gpt-4o-mini"

# Modelo para respostas complexas (poderoso)
OPENAI_RESPONSE_MODEL="gpt-4o"

# Modelo padr√£o (fallback)
OPENAI_MODEL="gpt-4o"
```

## üéØ Op√ß√µes de Configura√ß√£o

### Op√ß√£o 1: Econ√¥mico (Recomendado)
```bash
OPENAI_CLASSIFICATION_MODEL="gpt-4o-mini"  # Classifica√ß√£o
OPENAI_RESPONSE_MODEL="gpt-4o"            # Respostas
```
**Resultado:** R√°pido e barato, qualidade excelente

### Op√ß√£o 2: M√°xima Qualidade
```bash
OPENAI_CLASSIFICATION_MODEL="gpt-4o"       # Classifica√ß√£o
OPENAI_RESPONSE_MODEL="gpt-4-turbo"       # Respostas
```
**Resultado:** Melhor qualidade poss√≠vel, mais caro

### Op√ß√£o 3: Super Econ√¥mico
```bash
OPENAI_CLASSIFICATION_MODEL="gpt-4o-mini"  # Classifica√ß√£o
OPENAI_RESPONSE_MODEL="gpt-4o-mini"       # Respostas
```
**Resultado:** Muito barato, qualidade ainda boa

### Op√ß√£o 4: Racioc√≠nio Complexo (Casos Especiais)
```bash
OPENAI_CLASSIFICATION_MODEL="gpt-4o-mini"  # Classifica√ß√£o
OPENAI_RESPONSE_MODEL="o1-preview"        # Respostas
```
**Resultado:** Racioc√≠nio avan√ßado, muito caro, n√£o recomendado para conversa√ß√£o

## üîß Como Funciona

### Fluxo de Classifica√ß√£o (gpt-4o-mini):

```
USER: "tenho encaminhamento pra fisioterapia"
       ‚Üì
[GPT-4o-mini] Classifica: intent_port="5" (AGENDAR)
              Brief: "√ìtimo! Voc√™ tem encaminhamento..."
       ‚Üì
Bot usa o brief ou melhora com dados reais
```

**Tempo**: ~500ms
**Custo**: ~$0.0002

### Fluxo de Resposta Complexa (gpt-4o):

```
USER: "me explique o que √© RPG e como funciona"
       ‚Üì
[GPT-4o] Gera resposta rica e detalhada com contexto
       ‚Üì
Bot retorna resposta completa e bem formatada
```

**Tempo**: ~1000ms
**Custo**: ~$0.002

## üìù Arquivos Modificados

1. `.env` - Adicionadas vari√°veis de configura√ß√£o
2. `src/services/workflow/executors/gptExecutor.ts` - Usa OPENAI_CLASSIFICATION_MODEL
3. `src/services/workflow/executors/gptResponseExecutor.ts` - Usa OPENAI_RESPONSE_MODEL

## üöÄ Para Testar Diferentes Modelos

### Teste 1: Padr√£o (Econ√¥mico)
```bash
# .env
OPENAI_CLASSIFICATION_MODEL="gpt-4o-mini"
OPENAI_RESPONSE_MODEL="gpt-4o"
```

### Teste 2: M√°xima Qualidade
```bash
# .env
OPENAI_CLASSIFICATION_MODEL="gpt-4o"
OPENAI_RESPONSE_MODEL="gpt-4-turbo"
```

Reinicie o servidor e teste!

## üí° Recomenda√ß√µes

### Para Produ√ß√£o (Recomendado):
```bash
OPENAI_CLASSIFICATION_MODEL="gpt-4o-mini"  # Economia
OPENAI_RESPONSE_MODEL="gpt-4o"            # Qualidade
```

### Para Desenvolvimento/Testes:
```bash
OPENAI_CLASSIFICATION_MODEL="gpt-4o-mini"
OPENAI_RESPONSE_MODEL="gpt-4o-mini"  # Mais barato para testes
```

### Para Casos Especiais (Respostas Muito Complexas):
```bash
OPENAI_CLASSIFICATION_MODEL="gpt-4o-mini"
OPENAI_RESPONSE_MODEL="gpt-4-turbo"  # Melhor para respostas muito elaboradas
```

## ‚ö° Performance e Custos

### Estimativa para 1000 conversas/dia:

**Configura√ß√£o Econ√¥mica (Recomendado):**
- Classifica√ß√µes: 1000 √ó $0.0002 = $0.20/dia
- Respostas: 200 √ó $0.002 = $0.40/dia
- **Total: ~$0.60/dia = $18/m√™s**

**Configura√ß√£o M√°xima Qualidade:**
- Classifica√ß√µes: 1000 √ó $0.002 = $2.00/dia
- Respostas: 200 √ó $0.02 = $4.00/dia
- **Total: ~$6/dia = $180/m√™s**

## ‚úÖ Benef√≠cios

- ‚úÖ **90% de economia** na classifica√ß√£o de inten√ß√£o
- ‚úÖ **Mesma qualidade** nas respostas ricas
- ‚úÖ **Mais r√°pido** (gpt-4o-mini responde em ~500ms)
- ‚úÖ **Flex√≠vel** - configure conforme necessidade
- ‚úÖ **Escal√°vel** - economize conforme volume cresce

---

**Status:** Implementado e configur√°vel via .env! üöÄ

**Modelo Padr√£o Ativo:**
- Classifica√ß√£o: gpt-4o-mini
- Respostas: gpt-4o

